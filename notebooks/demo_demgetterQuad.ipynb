{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of DEM Download for 24k Quadrangle Maps ##\n",
    "\n",
    "This notebook provides simple examples of how to search for, download, and merge geospatial data products within a 24k quadrangle from The National Map (TNM). Information about available quad names can be found at https://www.usgs.gov/faqs/where-can-i-find-indexes-usgs-topographic-maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..') #path to the script we need (the dem_getter directory)\n",
    "\n",
    "from dem_getter import dem_getter as dg #repository for functions to request/download/merge geospatial data from TNM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fetch geospatial products, the user has to input the dataset type they are interested in. There are several datasets available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets are: ['DEM_1m', 'DEM_5m', 'NED_1-9as', 'NED_1-3as', 'NED_1as', 'NED_2as', 'LPC', 'OPR']\n"
     ]
    }
   ],
   "source": [
    "print('Available datasets are: {}'.format(list(dg.DATASETS_DICT.keys())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about the available datasets can be found at https://www.usgs.gov/3d-elevation-program/about-3dep-products-services. A map showing product coverage is available at https://apps.nationalmap.gov/lidar-explorer/#/."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Defaults and Optional Inputs ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each search is limited by a maximum number of products to be returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of products returned is: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"The maximum number of products returned is: \"+ str(dg.MAXITEMS))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, users can input a file name where the list of download paths can be saved, which the function will create if it doesn't already exist. By default, the code returns these paths as a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDlPaths=os.path.join('..','test_data','test_downloads')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can also specify the type of data they want returned. Different resolutions of data have the following options available:  \n",
    "\n",
    "**STANDARD DEMS**  \n",
    "\n",
    "* 1 meter DEM - GeoTIFF, IMG                 \n",
    "    `Dataset code: 'DEM_1m'`\n",
    "* 5 meter DEM (Alaska only) - Varies         \n",
    "    `Dataset code: 'DEM_5m'`\n",
    "* NED 1/9 arc-second (3 m) - IMG             \n",
    "    `Dataset code: 'NED_1-9as'`\n",
    "* NED 1/3 arc-second (10 m) - GeoTIFF        \n",
    "    `Dataset code: 'NED_1-3as'`\n",
    "* NED 1 arc-second (30 m) – GeoTIFF         \n",
    "     `Dataset code: 'NED_1as'`\n",
    "* NED 2 arc-second (Alaska – 60 m) - GeoTIFF   \n",
    "     `Dataset code: 'NED_2as'`  \n",
    "\n",
    "**SOURCE DATA PRODUCTS**  \n",
    "  \n",
    "* Lidar Point Cloud (LPC) – LAS, LAZ         \n",
    "     `Dataset code: 'LPC'`  \n",
    "* Original Product Resolution (OPR) - Varies  \n",
    "     `Dataset code: 'OPR'`\n",
    "\n",
    "Finally, some searches return products with the same spatial extent; the default setting for the parameter do_exclude_redundant_data returns only the most current version of the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Example Product Queries  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/13/TIFF/historical/n43w119/USGS_13_n43w119_20221128.tif']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data from the Andrews quad in Oregon\n",
    "dg.get_aws_paths_from_24kQuadName(dataset='NED_1-3as', quadName='Andrews',stateName = 'Oregon',filePath= saveDlPaths,dataType=\"GeoTIFF\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invalid quad names and searches that return no products will notify the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Quad name NotaName in Notafornia is not available. Check spelling or try another name.\n",
      "'NoneType' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "#invalid quad name\n",
    "try:\n",
    "    dg.get_aws_paths_from_24kQuadName(dataset='NED_1-3as', quadName='NotaName', stateName='Notafornia')\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No products available API request to: https://tnmaccess.nationalmap.gov/api/v1/products?, with parameters: {'prodFormats': '', 'polygon': '-118.50001321778488 42.37500564326506, -118.62501323980115 42.375005631983356, -118.6250132604624 42.500005642058625, -118.50001323844612 42.50000565331789, -118.50001321778488 42.37500564326506', 'datasets': 'Alaska IFSAR 5 meter DEM'}\n"
     ]
    }
   ],
   "source": [
    "#combination of dataset and quad name that returns no results\n",
    "try:\n",
    "    dg.get_aws_paths_from_24kQuadName(dataset='DEM_5m', quadName='Andrews',stateName='Oregon')\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the function will halt if the user inputs an incorrect dataset or a datatype that doesn't go with a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Warning, bad_dataset is not available. Available datasets are: ['DEM_1m', 'DEM_5m', 'NED_1-9as', 'NED_1-3as', 'NED_1as', 'NED_2as', 'LPC', 'OPR']\"\n"
     ]
    }
   ],
   "source": [
    "#searching for datasets not included in DATASETS_DICT raises a KeyError\n",
    "#Here we are just 'catching' the error and printing as a string to avoid showing the full traceback\n",
    "#in the notebook results\n",
    "try:\n",
    "    dl_list=dg.get_aws_paths_from_24kQuadName('bad_dataset','Andrews','Oregon')\n",
    "except KeyError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, GeoTIFF is not available. Available datatypes for LPC are LAS, LAZ, or LAS,LAZ\n"
     ]
    }
   ],
   "source": [
    "#if searching for LPC products and datatype is specified, it must be LAS or LAZ, or LAS,LAZ.\n",
    "#Quad map Kinikinik in Colorado\n",
    "\n",
    "#Again, the try/except here is to avoid showing the full traceback\n",
    "try:\n",
    "    dg.get_aws_paths_from_24kQuadName('LPC','Kinikinik', 'Colorado',dataType='GeoTIFF')\n",
    "\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of the first five products: ['https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/CO_CameronPeakWildfire_2021_D21/CO_CameronPkFire_1_2021/LAZ/USGS_LPC_CO_CameronPeakWildfire_2021_D21_w2965n1505.laz', 'https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/CO_DRCOG_2020_B20/CO_DRCOG_3_2020/LAZ/USGS_LPC_CO_DRCOG_2020_B20_w0447n4510.laz', 'https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/CO_NorthwestCO_2020_D20/CO_NWCO_2_2020/LAZ/USGS_LPC_CO_NorthwestCO_2020_D20_w2935n1510.laz']\n"
     ]
    }
   ],
   "source": [
    "#same search as above with the correct data type input\n",
    "dl_list=dg.get_aws_paths_from_24kQuadName('LPC','Kinikinik','Colorado', dataType='LAS,LAZ')\n",
    "print(\"Preview of the first five products: \"+str(dl_list[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for paths within multiple quads and compile a list of all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products returned: 71\n",
      "Number of unique products: 43\n",
      "Preview of the first five products: ['https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1m/Projects/CO_DRCOG_2020_B20/TIFF/USGS_1M_13_x43y451_CO_DRCOG_2020_B20.tif', 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1m/Projects/CO_NorthwestCO_2020_D20/TIFF/USGS_1M_13_x44y452_CO_NorthwestCO_2020_D20.tif', 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1m/Projects/CO_DRCOG_2020_B20/TIFF/USGS_1M_13_x44y452_CO_DRCOG_2020_B20.tif', 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1m/Projects/CO_NorthwestCO_2020_D20/TIFF/USGS_1M_13_x47y452_CO_NorthwestCO_2020_D20.tif', 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1m/Projects/CO_SoPlatteRiver_Lot2b_2013/TIFF/USGS_one_meter_x45y452_CO_SoPlatteRiver_Lot2b_2013.tif']\n"
     ]
    }
   ],
   "source": [
    "#test names to query-- adjacent quads in CO\n",
    "quad_names = ['Kinikinik','Rustic', 'Big Narrows','Poudre Park']\n",
    "\n",
    "dl_list=[]\n",
    "for name in quad_names:\n",
    "    paths= dg.get_aws_paths_from_24kQuadName(dataset='DEM_1m',quadName=name,stateName='Colorado')\n",
    "    \n",
    "    if paths: #skips if there are no available products\n",
    "        for path in paths:\n",
    "            dl_list.append(path) #master list of file paths\n",
    "\n",
    "#adjacent quads might return some of the same data products;\n",
    "# delete duplicates\n",
    "dl_list_unique=[*set(dl_list)]\n",
    "        \n",
    "print(\"Number of products returned: \"+str(len(dl_list)))\n",
    "print(\"Number of unique products: \"+str(len(dl_list_unique)))\n",
    "print(\"Preview of the first five products: \"+str(dl_list_unique[:5]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and Merging Data ###\n",
    "\n",
    "The following section will demonstrate how to download and merge data, using a list of download paths that can be fetched with any of the functions described above.\n",
    "\n",
    "To use the download function, the user must input:\n",
    "* **List of download paths**\n",
    "* **Folder name to save the data to**\n",
    "    * If the input folder name does not exist, the function will create it\n",
    "  \n",
    "The batch_download function checks the size of the fetched data, and queries the user to continue with the download or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: USGS_13_n36w082_20220512.tif\n",
      "Working on: USGS_13_n36w083_20220512.tif\n"
     ]
    }
   ],
   "source": [
    "#fetch paths\n",
    "dl_list=dg.get_aws_paths_from_24kQuadName(dataset=\"NED_1-3as\",\n",
    "                                          quadName=\"Little Switzerland\",\n",
    "                                           stateName= 'North Carolina',\n",
    "                                           filePath=None,\n",
    "                                           dataType='GeoTIFF',\n",
    "                                           doExcludeRedundantData=True)\n",
    "\n",
    "#download\n",
    "saved_paths=dg.batch_download(dl_list,os.path.join('..','test_data','test_downloads'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These downloaded products can now be merged together. The merge function requires:\n",
    "* **Input file list**\n",
    "    * A list of all the filenames to merge\n",
    "* **Output file path**\n",
    "    * New file name and path to save the data as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_warp_dems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minFileNames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moutFileName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moutExtent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moutEPSG\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpixelSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdoReturnGdalSourceResult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mresampleAlg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cubic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnoDataValue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'GTiff'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Wrapper for gdal.Warp, an image mosaicing, reprojection and cropping function\n",
      "\n",
      "Args:\n",
      "    inFileNames (list): A list of all the filenames to merge\n",
      "    outFileName (str): the output path to save the file as\n",
      "    outExtent (list OR tuple, optional): ([minx, maxx], [miny, maxy]). Defaults to None.\n",
      "    outEPSG (int, optional): EPSG code for the coordinate system of the specified output extent (also sets the output\n",
      "        coordinate system). Defaults to None.\n",
      "    pixelSize (float, optional):  Dimension of the output pixel (x and y direction) in the native units of the\n",
      "        output coordinate system. Defaults to None.\n",
      "    doReturnGdalSourceResult (bool, optional): If True returns the gdal source object for the newly created dataset. \n",
      "        If False (the default) returns none and closes the connection to the newly created dataset. Defaults to False.\n",
      "    resampleAlg (str, optional): The resampling algorithm to use in reprojecting and merging the raster. Can be\n",
      "        any option allowed by GDAL. Prefered options will likely be: 'near', 'bilinear', 'cubic', 'cubicspline',\n",
      "        'average'. Defaults to 'cubic'.\n",
      "    noDataValue (float, optional): No data value to use for the input and output data. Defaults to None.\n",
      "    format (str, optional): File format to save the output dataset as. Defaults to 'GTiff'.\n",
      "\n",
      "Returns:\n",
      "    gridSource (None OR gdal.Dataset): If doReturnGdalSource is False, returns None. If doReturnGdalSource is True\n",
      "        will instead return a gdal.Dataset instance representing the input raster after application of the warp.\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\sjohnstone\\onedrive - doi\\documents\\datatools\\dem_getter\\dem_getter\\dem_getter\\dem_getter.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "#You can also check the function doctstrings for more information\n",
    "dg.merge_warp_dems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sjohnstone\\AppData\\Local\\miniconda3\\envs\\gisdb\\Lib\\site-packages\\osgeo\\gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#now we'll merge together those downloaded files  \n",
    "dg.merge_warp_dems(saved_paths,os.path.join('..','test_data','test_downloads','NCmerge.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below provides a quick way to fetch, download, and merge data from multiple quads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: USGS_13_n43w119_20221128.tif\n",
      "Working on: USGS_13_n44w119_20231102.tif\n",
      "Working on: USGS_13_n44w118_20170417.tif\n"
     ]
    }
   ],
   "source": [
    "#list of two quad names\n",
    "quad_names = ['Andrews', 'Juntura']\n",
    "state = 'Oregon'\n",
    "#download\n",
    "full_filelist=[]\n",
    "for name in quad_names:\n",
    "    paths= dg.get_aws_paths_from_24kQuadName('NED_1-3as',name,'Oregon')\n",
    "\n",
    "    if paths: #skips if polygon has no available products\n",
    "        filelist=dg.batch_download(paths,os.path.join('..','test_data','test_downloads')) #downloads files\n",
    "        for file in filelist:\n",
    "            full_filelist.append(file) #master list of file paths for merging\n",
    "\n",
    "dg.merge_warp_dems(full_filelist,os.path.join('..','test_data','test_downloads','quad_merge.tif'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2963f68853807b8ed2d6ba174196e13d966fabc9b2e87680f5adf13c54295805"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
